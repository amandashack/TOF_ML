# ==============================================================================
# Base config for training pipeline
# This file can be updated by the user or read from command line args.
# ==============================================================================

# ------------------------------------------------------------------------------
# 1. DATA LOADING
#    - The "directory" might determine which loader to use in your code
#    - Example: If the directory contains "simion" data, it might use SimionDataLoader
# ------------------------------------------------------------------------------
# Vandana's continuous data
# "/sdf/home/v/vkaushik/Sim_csv_files/0.5eV_resolution"
# "vandana_continuous_nm"

# old discrete data subset
# C:\Users\proxi\Documents\coding\TOF_data
# "old_discrete"

data:
  directory: C:\Users\proxi\Documents\coding\TOF_data      # Path or identifier to the raw data directory
  loader_config_key: old_discrete     # The key that indicates which loader block
  parameters:
    mid1: none                     # Example metadata param for loader
    mid2: none                     # Example metadata param for loader
    retardation_range: none     # Example range
    number_of_samples: 10000000       # Example data size or sampling specification

# ------------------------------------------------------------------------
# 2. DATA SPLITTING CONFIGURATION
#    - Which approach to use for splitting (e.g. UniformSplitter, SubsetSplitter)
#    - Parameters relevant to each approach
# ------------------------------------------------------------------------
data_splitting:
  type: UniformSplitter
  subset_column: initial_ke
  subset_values: [1, 10, 100, 500]
  train_fraction_for_subset: 0.6
  val_fraction: 0.2
  test_fraction: 0.2
  random_state: 42

# ------------------------------------------------------------------------------
# 3. FEATURE CONFIGURATION
#    - Which columns are used as features (inputs)
#    - Which column is the target (output)
#    - Whether we generate interaction terms
# ------------------------------------------------------------------------------
features:
  input_columns: ['tof', 'mid1', 'mid2', 'retardation']
  output_column: initial_ke
  generate_interactions: true

# ------------------------------------------------------------------------------
# 4. SCALING CONFIGURATION
#    - If you want to apply a scaler, specify which kind
#    - Options might include "StandardScaler", "MinMaxScaler", "None"
# ------------------------------------------------------------------------------
scaler:
  type: MinMaxScaler

# ------------------------------------------------------------------------------
# 5. TRAINING PARAMETERS
#    - General training settings (split size, random seed, etc.)
# ------------------------------------------------------------------------------
training:
  test_size: 0.2
  random_state: 42

# ------------------------------------------------------------------------------
# 6. MODEL CONFIGURATION
#    - Which model to use (e.g., "MLPRegressor", "RandomForestRegressor")
#    - Hyperparameters for that model
# ------------------------------------------------------------------------------
model:
  type: "MLPRegressor"  # or "RandomForestRegressor" in the future
  params:
    hidden_layers: [16, 16, 16, 16, 16]   # Example: 3 layers with 32->64->32
    activations: ['relu', 'relu', 'relu', 'relu', 'relu']  # corresponding activation per layer
    learning_rate: 0.05
    epochs: 100
    batch_size: 32

# ------------------------------------------------------------------------------
# 7. MODEL OUTPUT DIRECTORY
#    - Where would you like to save the model??
# ------------------------------------------------------------------------------
model_output_dir: /sdf/scratch/users/a/ajshack/hp_database
