model:
  type: MLPRegressor   # or "RandomForestRegressor", etc.
  params:
    hidden_layers: [64, 64]
    activation: relu
    learning_rate: 0.001
    # ... add more hyperparameters

training:
  test_size: 0.2
  random_state: 42
  scaler: StandardScaler  # or "MinMaxScaler", "None", etc.
  epochs: 100               # for NN training
  batch_size: 32
  # ... other training-related configs

features:
  input_columns: ['tof', 'retardation']
  generate_interactions: true
  output_column: initial_ke
